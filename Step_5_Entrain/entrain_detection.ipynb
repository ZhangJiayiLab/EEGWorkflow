{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrain Detection\n",
    "using entrain window detection method.\n",
    "<!--accelerated by `multiprocessing`-->\n",
    "\n",
    "- preview single channel\n",
    "- group export all channels all days into `.mat` files\n",
    "- group export all channels all days restore from `.mat` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "import EEGAnalysis as ea\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import re, os\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patient_id = 'zhangchen'\n",
    "\n",
    "ea_manager = ea.DataManager('/media/STORAGE/EEG/Data')  ## create data manager\n",
    "patient = ea_manager.create_patient(patient_id)  ## create new patient\n",
    "# patient = ea_manager.get_patient(patient_id)  ## load previous patient\n",
    "\n",
    "##### Constants #####\n",
    "_freq = 2000\n",
    "ROI = (-3, 3)\n",
    "EntrainWindow = (-1, 1)\n",
    "EntrainThresh = 1.96\n",
    "\n",
    "zbase = (-2,-1)\n",
    "tspec = np.linspace(ROI[0], ROI[1], int(_freq)*(ROI[1]-ROI[0]))\n",
    "\n",
    "## Bandpass ##\n",
    "nyq = _freq / 2.0\n",
    "width = 5.0 / nyq\n",
    "ripple_db = 60.0\n",
    "\n",
    "# Compute the order and Kaiser parameter for the FIR filter.\n",
    "N, beta = signal.kaiserord(ripple_db, width)\n",
    "taps = signal.firwin(N, [50/nyq, 80/nyq],window=('kaiser', beta),pass_zero=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_entrain(chidx):\n",
    "    _data_list = patient.load_isplit(chidx)\n",
    "    _dates = _data_list.keys()\n",
    "\n",
    "    # _result = np.zeros((np.size(frange, 0), np.size(tspec)))\n",
    "    # _valid_count = 0\n",
    "\n",
    "    _result = {'chidx':chidx, 'date':[], 'trace':[], 'detection':[], 'latency':[], 'amplitude':[]}\n",
    "    for _idate in _dates:\n",
    "\n",
    "        _data = _data_list[_idate]['value']\n",
    "        \n",
    "        _filtered = signal.hilbert(signal.filtfilt(taps, 1, _data))\n",
    "\n",
    "        # first 20 markers for 10 sec trials, last 20 for 5 sec trials\n",
    "        _marker = patient.get_marker(file=_idate)[20:]\n",
    "        _entrain_marker = [np.mean(np.diff(_marker)) + _marker[-1]]\n",
    "        \n",
    "        _epoch = ea.create_1d_epoch_bymarker(_data, _entrain_marker, ROI, _freq).reshape((1,1,-1))\n",
    "        entry_power = ea.decomposition.dwt_power(_epoch, _freq, baseline=(zbase[0]-ROI[0], zbase[1]-ROI[0]))\n",
    "        \n",
    "        _smooth = ea.decomposition.gaussianwind(entry_power[0], 2000, 0.05)\n",
    "        _entrain = np.max(_smooth[(tspec > EntrainWindow[0]) & (tspec < EntrainWindow[1])]) > 1.96 and\\\n",
    "                   np.max(_smooth[(tspec < EntrainWindow[0]) | (tspec > EntrainWindow[1])]) < 1.96\n",
    "        \n",
    "        _latency = np.argmax(_smooth[(tspec > EntrainWindow[0]) & (tspec < EntrainWindow[1])]) / 2000 - EntrainWindow[0]\n",
    "        _amplitude = np.max(_smooth[(tspec > EntrainWindow[0]) & (tspec < EntrainWindow[1])])\n",
    "        \n",
    "        _result['latency'].append(_latency)\n",
    "        _result['amplitude'].append(_amplitude)\n",
    "        _result['trace'].append(_smooth)\n",
    "        _result['detection'].append(_entrain)\n",
    "        _result['date'].append(_idate)\n",
    "        \n",
    "    _result['trace'] = np.array(_result['trace'])\n",
    "    _result['detection'] = np.array(_result['detection'])\n",
    "    _result['latency'] = np.array(_result['latency'])\n",
    "    _result['amplitude'] = np.array(_result['amplitude'])\n",
    "\n",
    "    return _result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_total_ch = len(patient._sgch_config['chidx'])\n",
    "with Pool(processes=5) as _pool:\n",
    "    _output = list(tqdm(_pool.imap_unordered(detect_entrain, range(_total_ch)), total=_total_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_dates = np.array([item['date'] for item in _output])\n",
    "_entrain = np.array([item['detection'] for item in _output])\n",
    "_latency = np.array([item['latency'] for item in _output])\n",
    "_amplitude = np.array([item['amplitude'] for item in _output])\n",
    "_trace = np.array([item['trace'] for item in _output])\n",
    "\n",
    "with h5py.File('./export/%s_entrain.h5'%patient_id, 'w') as _f:\n",
    "    _f.create_dataset(_dates[:, 0::3][0][0][-1], data=_entrain[:, 0::3])\n",
    "    _f.create_dataset(_dates[:, 1::3][0][0][-1], data=_entrain[:, 1::3])\n",
    "    _f.create_dataset(_dates[:, 2::3][0][0][-1], data=_entrain[:, 2::3])\n",
    "    \n",
    "savemat('./export/%s_entrain.mat'%patient_id, {'1':_entrain[:, 0::3],'2':_entrain[:, 1::3],'3':_entrain[:, 2::3]})\n",
    "savemat('./export/%s_latency.mat'%patient_id, {'1':_latency[:, 0::3],'2':_latency[:, 1::3],'3':_latency[:, 2::3]})\n",
    "savemat('./export/%s_amplitude.mat'%patient_id, {'1':_amplitude[:, 0::3],'2':_amplitude[:, 1::3],'3':_amplitude[:, 2::3]})\n",
    "\n",
    "with h5py.File('./export/%s_entrain_trace.h5'%patient_id, 'w') as _f:\n",
    "    for item in _output:\n",
    "        _g = _f.create_group('%03d'%item['chidx'])\n",
    "        _g.create_dataset('date', data=np.array(item['date'], dtype='S'))\n",
    "        _g.create_dataset('trace', data=item['trace'], compression='gzip')\n",
    "\n",
    "k = dict([('channel%03d'%item['chidx'], item)for item in _output])\n",
    "save('./export/%s_entrain_trace.mat'%patient_id, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
